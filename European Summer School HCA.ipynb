{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7ec165f6",
   "metadata": {},
   "source": [
    "# European Summer School in Chinese Digital Humanities\n",
    "\n",
    "## Stylometry: HCA\n",
    "In this notebook I will introduce a script that will allow you to conduct stylometric analysis by only changing a few options. This notebook will perform heirarchical cluster analysis.\n",
    "\n",
    "### The imports\n",
    "There are a number of items from various Python librarys that we need to import to conduct the analysis we are interested in. It is, of course, possible for us to write all of the code necessary for this ourselves, but it is much preferable to rely on things that other people have created for us."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8beda25",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Library for loading data\n",
    "import os\n",
    "\n",
    "# Libraries for analysis\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from scipy.spatial.distance import pdist\n",
    "from scipy.cluster.hierarchy import linkage, dendrogram\n",
    "\n",
    "# Library for visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Custom local modules with useful utilities\n",
    "from clean import clean # for cleaning the text\n",
    "from totrad import Convert # to convert to tradtitional characters"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed56baf3",
   "metadata": {},
   "source": [
    "### Set analysis options\n",
    "\n",
    "#### corpus_folder_name\n",
    "Provide the name of the corpus folder in a string. Leave as \"demo_corpus\" to use the supplied corpus.\n",
    "\n",
    "#### analysis_vocab_file\n",
    "If you want to provide a custom set of words to use for the analysis provide the name of a text file that contains the words, one word to a line. This should be a string like\n",
    "\"analysis_vocab.txt\"\n",
    "\n",
    "#### most_common_words\n",
    "Set the number of most common terms to use for your analysis. This is ignored if you provide a vocab file. By default this is set to None, which will analyze every word in the corpus. This should be an integer like\n",
    "100\n",
    "\n",
    "#### n_gram:\n",
    "By default this is set to work on <i>n</i>-grams where n is 1, meaning individual characters will be at the root of the analysis. You are welcome to play with around with this as you see fit. The higher the n, the sparser the data.\n",
    "\n",
    "#### convert_to_traditional\n",
    "Set this to False to not modify the characters in the files. Set it to True if you would like to perform autoconversion\n",
    "\n",
    "\n",
    "#### label_types\n",
    "This is a tuple of strings that describe the metadata convention you are using to name your corpus. This assumes that you have followed the naming convention I suggested in my overview.\n",
    "\n",
    "#### color_value:\n",
    "Here you will set the INDEX of the feature you want to highlight in color. Remember that Python indexing starts at 0, so for the default demo corpus 0 will be title, 1 will be dynasty, 2 will be siku, 3 will be subcat, and 4 will be author. It is good practice to use color only when there are relatively few unique values, so I would suggest only using 1, 2, or 3 here.\n",
    "\n",
    "#### label_value:\n",
    "This is the INDEX of the feature you want to use as the leaf label in the dendrogram. The same indexes as color value apply, but any of them are find. I generally find title to be the most informative, but you could easily also pair siku color with dynasty label (or vice versa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9739638",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_folder_name = \"demo_corpus\"\n",
    "\n",
    "analysis_vocab_file = None\n",
    "\n",
    "most_common_words = 100\n",
    "\n",
    "n_gram = 1\n",
    "\n",
    "convert_to_traditional = False\n",
    "\n",
    "# Types of labels for documents in the corpus\n",
    "# This must match your metadata naming scheme!\n",
    "label_types = ('title', 'dynasty', 'siku', 'subcat', 'author') # tuple with strings\n",
    "\n",
    "# Some of these labels will set the color used to differentiate the points in the plot.\n",
    "# The label at this index is used to set Color:\n",
    "color_value = 3 # Index of label to use for color (integer). Here 3 points to \"subcat\"\n",
    "\n",
    "# What do you want to use to label the dendrogram?\n",
    "label_value = 0 # 0 selects title\n",
    "\n",
    "# Set font to use for graph. By default matplotlib does not work well with Chinese, so you will have to set this manually.\n",
    "# For macs: Heiti TC\n",
    "# For windows: SimHei\n",
    "font_to_use = \"Heiti TC\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b9a54ac",
   "metadata": {},
   "source": [
    "From this point on you don't need to change any of the code to run the analysis, but you are welcome to mix things up if you like."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f89df0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create containers for the data\n",
    "texts, labels = [], []\n",
    "\n",
    "# Set up text converter if so desired\n",
    "if convert_to_traditional:\n",
    "    c = Convert(preserve_multiple=False)\n",
    "\n",
    "if analysis_vocab_file:\n",
    "    with open(analysis_vocab_file, 'r', encoding='utf8') as rf:\n",
    "        vocab = [v for v in rf.read().split(\"\\n\") if v != \"\"]\n",
    "else:\n",
    "    vocab = None\n",
    "\n",
    "\n",
    "    \n",
    "# go through every file in the demo corpus\n",
    "for root, dirs, files in os.walk(corpus_folder_name):\n",
    "  for fname in files:\n",
    "    # check that the file in question is a .txt file\n",
    "    if fname.endswith(\".txt\"):\n",
    "      # open the file\n",
    "      with open(os.path.join(root, fname), 'r', encoding='utf8') as rf:\n",
    "\n",
    "        # clean filename\n",
    "        fname = fname[:-4]\n",
    "            \n",
    "        # read and clean the file and append it to the texts list\n",
    "        text = clean(rf.read())\n",
    "        \n",
    "        \n",
    "        # if covert_to_traditional is set to True, convert\n",
    "        if convert_to_traditional:\n",
    "            fname = c.to_trad(fname)\n",
    "            text = c.to_trad(text)\n",
    "        \n",
    "        # append to text list\n",
    "        texts.append(text)\n",
    "\n",
    "        # extract the metadata from the name of the file\n",
    "        labels.append(fname.split(\"_\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5d65c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run the analysis\n",
    "vectorizer = TfidfVectorizer(ngram_range=(n_gram, n_gram), vocabulary=vocab, max_features=most_common_words, use_idf=False, analyzer=\"char\")\n",
    "\n",
    "vecs = vectorizer.fit_transform(texts)\n",
    "vecs = vecs.toarray()\n",
    "distances = pdist(vecs,metric='euclidean')\n",
    "\n",
    "linkages = linkage(distances,'ward')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b977073",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "plt.rcParams['font.sans-serif'] = [font_to_use]\n",
    "plt.rcParams[\"figure.figsize\"] = (10,15)\n",
    "dendrogram(linkages, labels=[l[label_value] for l in labels], orientation=\"left\", leaf_font_size=14)\n",
    "plt.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n",
    "plt.tight_layout()\n",
    "\n",
    "# let's get an axis object so we can manipulate the color of the labels\n",
    "ax = plt.gca()\n",
    "# get the labels\n",
    "tick_labels = ax.get_ymajorticklabels()\n",
    "\n",
    "# find all the unique values for each of the label types\n",
    "unique_label_values = set([l[color_value] for l in labels])\n",
    "\n",
    "# create color dictionaries for all labels\n",
    "color_dictionaries = []\n",
    "colorpalette = sns.color_palette(\"husl\",len(unique_label_values)).as_hex()\n",
    "color_dictionary = dict(zip(unique_label_values,colorpalette))\n",
    "    \n",
    "title_to_feature = {t:f for t,f in zip([l[label_value] for l in labels], [l[color_value] for l in labels])}\n",
    "\n",
    "\n",
    "# iterate through each label and set its color based on the dictionaries we set\n",
    "# up earlier\n",
    "for label in tick_labels:\n",
    "    label.set_color(color_dictionary[title_to_feature[label.get_text()]])\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
